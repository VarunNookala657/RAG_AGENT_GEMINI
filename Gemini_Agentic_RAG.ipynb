{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Gemini Agentic RAG Model**"
      ],
      "metadata": {
        "id": "_7eICKE_7B8F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2w2ROled-P8",
        "outputId": "17590875-3e68-47c6-b346-8a7517d322d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries installed and imported successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# --- Installations ---\n",
        "# Core LLM libraries\n",
        "!pip install -qqq torch transformers accelerate bitsandbytes\n",
        "# LangChain core\n",
        "!pip install -qqq langchain\n",
        "# LangChain community for HuggingFacePipeline and potentially other local integrations\n",
        "!pip install -qqq langchain-community\n",
        "# For local embedding models (sentence-transformers is a common choice)\n",
        "!pip install -qqq sentence-transformers\n",
        "# Vector store - ChromaDB\n",
        "!pip install -qqq chromadb\n",
        "# Document loading from web\n",
        "!pip install -qqq beautifulsoup4 # for WebBaseLoader's dependency bs4\n",
        "\n",
        "\n",
        "!pip install -qqq tiktoken\n",
        "# For environment variables\n",
        "!pip install -qqq python-dotenv\n",
        "\n",
        "\n",
        "\n",
        "# --- Imports ---\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Modified LangChain imports for local models\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langchain_community.llms import HuggingFacePipeline\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings # For local embeddings\n",
        "\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.tools import tool\n",
        "from langchain.tools.render import render_text_description_and_args\n",
        "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
        "from langchain.agents.format_scratchpad import format_log_to_str\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "print(\"Libraries installed and imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gemini - LLM Model\n",
        "# --- Setup and LLM Initialization for Google Gemini API ---\n",
        "\n",
        "# --- CRITICAL: Comprehensive Installations\n",
        "# Ensure necessary LangChain components are correctly installed\n",
        "!pip uninstall -y langchain langchain-community langchain-google-genai langchain-core # Clean previous installs\n",
        "!pip install -qqq langchain        # Core LangChain\n",
        "!pip install -qqq langchain-community # For common components\n",
        "!pip install -qqq langchain-google-genai # For Google Gemini integration\n",
        "!pip install -qqq python-dotenv\n",
        "\n",
        "# Other dependencies the tutorial uses later (installing now to avoid future issues)\n",
        "!pip install -qqq chromadb\n",
        "!pip install -qqq beautifulsoup4\n",
        "!pip install -qqq tiktoken\n",
        "\n",
        "print(\"Required libraries installed.\")\n",
        "\n",
        "# --- Imports for LLM initialization ---\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI # Import for Gemini LLM\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# --- Set up your Google API Key ---\n",
        "load_dotenv(override=True) # Load any .env files\n",
        "\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCv-guHHFBdrunOlQ9h5aF2tgm6olm3MdE\"\n",
        "\n",
        "# Verify the API key is loaded\n",
        "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
        "if not GOOGLE_API_KEY:\n",
        "    raise ValueError(\"Google API Key not found. Please ensure it's set in os.environ or your .env file.\")\n",
        "\n",
        "# Define the Gemini model name\n",
        "GEMINI_MODEL_NAME = \"gemini-1.5-flash\" # 'gemini-pro' is the general text model\n",
        "\n",
        "print(f\"Google API Key and model name ({GEMINI_MODEL_NAME}) set.\")\n",
        "\n",
        "\n",
        "# Initialize the LLM with Google Gemini\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=GEMINI_MODEL_NAME,\n",
        "    temperature=0,\n",
        "    max_output_tokens=250,\n",
        "\n",
        ")\n",
        "\n",
        "print(\"LLM (Google Gemini) initialized.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jepfm5eerhRb",
        "outputId": "049c0666-5bbf-41b9-91af-a27b60bd3001"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 0.3.26\n",
            "Uninstalling langchain-0.3.26:\n",
            "  Successfully uninstalled langchain-0.3.26\n",
            "Found existing installation: langchain-community 0.3.26\n",
            "Uninstalling langchain-community-0.3.26:\n",
            "  Successfully uninstalled langchain-community-0.3.26\n",
            "\u001b[33mWARNING: Skipping langchain-google-genai as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: langchain-core 0.3.66\n",
            "Uninstalling langchain-core-0.3.66:\n",
            "  Successfully uninstalled langchain-core-0.3.66\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequired libraries installed.\n",
            "Google API Key and model name (gemini-1.5-flash) set.\n",
            "LLM (Google Gemini) initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set up a prompt template\n",
        "template = \"Answer the {query} accurately. If you do not know the answer, simply say you do not know.\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "print(\"Prompt template created.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EieceFZju42g",
        "outputId": "95be148b-8f49-4717-bef2-03075929797b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt template created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set up the chain with our prompt and our LLM\n",
        "agent = prompt | llm\n",
        "\n",
        "print(\"Agent chain created.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpTK8r4Fu468",
        "outputId": "98a4197c-17d8-4249-bef4-be5d5e85cdc5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent chain created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#agent.invoke({\"query\": 'What sport is played at the US Open?'})\n",
        "query1 = 'What sport is played at the US Open?'\n",
        "print(f\"\\nInvoking the agent with query: '{query1}'\")\n",
        "result1 = agent.invoke({\"query\": query1})\n",
        "print(\"Output:\", result1.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dpHQRK6vlnX",
        "outputId": "5774444f-7569-444f-a388-88e9ddca335e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Invoking the agent with query: 'What sport is played at the US Open?'\n",
            "Output: Tennis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = 'Where was the 2024 US Open Tennis Championship?'\n",
        "print(f\"\\nInvoking the agent with query: '{query2}'\")\n",
        "result2 = agent.invoke({\"query\": query2})\n",
        "print(\"Output:\", result2.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z509lML1vlpy",
        "outputId": "f6d53880-6b32-4f78-cfa4-d4d876aa2200"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Invoking the agent with query: 'Where was the 2024 US Open Tennis Championship?'\n",
            "Output: The 2024 US Open Tennis Championship was held at the USTA Billie Jean King National Tennis Center in Flushing Meadows, New York.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "query = 'Where was the 2025 US Open Tennis Championship?'\n",
        "print(f\"\\nInvoking the agent with query: '{query}'\")\n",
        "result = agent.invoke({\"query\": query})\n",
        "print(\"Output:\", result.content) # To get the plain text answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwvqZqL1vltT",
        "outputId": "329d0d15-51a6-4f16-bdb0-4b4eee90685e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Invoking the agent with query: 'Where was the 2025 US Open Tennis Championship?'\n",
            "Output: The 2025 US Open Tennis Championship has not yet been held.  Therefore, I do not know the answer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the agent with a new query ---\n",
        "query = 'Who won IPL 2025 CUP?'\n",
        "print(f\"\\nInvoking the agent with query: '{query}'\")\n",
        "result = agent.invoke({\"query\": query})\n",
        "print(\"Output:\", result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dIT-4VRznDG",
        "outputId": "06c511c3-660f-4b21-979a-a62f14ac1e31"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Invoking the agent with query: 'Who won IPL 2025 CUP?'\n",
            "Output: I do not know.  The IPL 2025 season has not yet been played.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5. Establish the knowledge base and retriever (Part 1 - IPL 2025 Focus) ---\n",
        "\n",
        "# Define the URLs for content extraction, focusing only on IPL 2025.\n",
        "urls = [\n",
        "    'https://www.jagranjosh.com/general-knowledge/ipl-2025-winner-rcb-royal-challengers-bengaluru-captain-coach-and-overall-performance-1748975062-1',\n",
        "    'https://timesofindia.indiatimes.com/sports/cricket/ipl/top-stories/ipl-winners-list-20082025-final-results-opponents-margins/articleshow/121604424.cms',\n",
        "    'https://www.hindustantimes.com/cricket/ipl-2025-awards-list-who-won-the-orange-cap-purple-cap-emerging-player-award-check-full-list-of-winners-101749010568299.html',\n",
        "    'https://en.wikipedia.org/wiki/2025_Indian_Premier_League' # Wikipedia is generally good for static content\n",
        "]\n",
        "\n",
        "# Load the documents using LangChain WebBaseLoader for the URLs we listed.\n",
        "print(\"Loading documents from IPL 2025 URLs... This may take a few moments.\")\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "print(\"Documents loaded.\")\n",
        "\n",
        "# Flatten the list of lists into a single list of documents.\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "# Print a sample document to verify content.\n",
        "if docs_list:\n",
        "    print(\"\\nSample document (first loaded page content) :\")\n",
        "    # Print first 1000 characters and metadata to get a good sense\n",
        "    print(docs_list[0].page_content[:1000])\n",
        "    print(docs_list[0].metadata)\n",
        "else:\n",
        "    print(\"No documents were loaded or docs_list is empty after loading.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2byNLmC1eBdv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb38143-a734-40d8-ea98-de0e913350c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading documents from IPL 2025 URLs... This may take a few moments.\n",
            "Documents loaded.\n",
            "\n",
            "Sample document (first loaded page content) :\n",
            "IPL 2025 Winner: Royal Challengers Bengaluru (RCB) won the 18th Edition of TATA IPL; Check Overall Team Performance Check MP Board 5th, 8th Re-Exam Result Here Check Results   School+UP BoardBihar BoardMP BoardRJ BoardMH BoardUK BoardHP BoardGJ BoardICSE BoardCollegesJobs+Sarkari NaukriSarkari ResultGKResults+JAC 12th ResultJAC Result 2025RBSE Result 2025CBSE 10th ResultCBSE 12th ResultExamsEducation NewsCurrent AffairsMock TestMore+‡§π‡§ø‡§®‡•ç‡§¶‡•ÄVideosShort VideosWeb StoriesSchoolCollegesJobsGKExamsResultsCurrent AffairsEducation NewsCBSEMock TestWeb Stories‡§π‡§ø‡§®‡•ç‡§¶‡•ÄVideosShort VideosFocusSRMU LucknowViksit BiharSanskriti UniversityJames Dyson AwardHealthcare DegreesMP Board ResultRPF ConstableLongest DayCampus Connect Quick Links School & Boards   College Admission   Govt Jobs Alert & Prep   Current Affairs  GK & Aptitude   Homegeneral knowledgeCurrent GKIPL 2025 Winner: Royal Challengers Bengaluru (RCB) won the 18th Edition of TATA IPL; Check Overall Team PerformanceIPL\n",
            "{'source': 'https://www.jagranjosh.com/general-knowledge/ipl-2025-winner-rcb-royal-challengers-bengaluru-captain-coach-and-overall-performance-1748975062-1', 'title': 'IPL 2025 Winner: Royal Challengers Bengaluru (RCB) won the 18th Edition of TATA IPL; Check Overall Team Performance ', 'description': 'Royal Challengers Bengaluru (RCB) clinched the IPL 2025 title, ending an 11-year wait to become champions in the 18th TATA IPL edition. Explore their stellar team performance, key players, and standout moments that led to their historic victory against RCB in the final.', 'language': 'en'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5. Establish the knowledge base and retriever (Part 2: Split documents) ---\n",
        "\n",
        "# Import the necessary splitter\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Initialize the text splitter using from_tiktoken_encoder\n",
        "# 'cl100k_base' is the encoding used by GPT-4, GPT-3.5-turbo, etc.\n",
        "# Chunk size and overlap are important parameters for RAG performance.\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=250, # Smaller chunks can be more precise\n",
        "    chunk_overlap=0   # No overlap for simplicity here, but overlap can improve context\n",
        ")\n",
        "\n",
        "# Apply the splitter to our loaded documents\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "print(f\"Number of original documents: {len(docs_list)}\")\n",
        "print(f\"Number of chunks after splitting: {len(doc_splits)}\")\n",
        "print(\"\\nSample chunk (first chunk content):\")\n",
        "print(doc_splits[0].page_content[:500]) # Print first 500 characters of the first chunk\n",
        "print(doc_splits[0].metadata)\n",
        "\n"
      ],
      "metadata": {
        "id": "xFsTL9OzeBfm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3aad41c-b0c3-4b2f-d633-b94aa3e26bae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of original documents: 4\n",
            "Number of chunks after splitting: 167\n",
            "\n",
            "Sample chunk (first chunk content):\n",
            "IPL 2025 Winner: Royal Challengers Bengaluru (RCB) won the 18th Edition of TATA IPL; Check Overall Team Performance Check MP Board 5th, 8th Re-Exam Result Here Check Results   School+UP BoardBihar BoardMP BoardRJ BoardMH BoardUK BoardHP BoardGJ BoardICSE BoardCollegesJobs+Sarkari NaukriSarkari ResultGKResults+JAC 12th ResultJAC Result 2025RBSE Result 2025CBSE 10th ResultCBSE 12th ResultExamsEducation NewsCurrent AffairsMock TestMore+‡§π‡§ø‡§®‡•ç‡§¶‡•ÄVideosShort VideosWeb StoriesSchoolCollegesJo\n",
            "{'source': 'https://www.jagranjosh.com/general-knowledge/ipl-2025-winner-rcb-royal-challengers-bengaluru-captain-coach-and-overall-performance-1748975062-1', 'title': 'IPL 2025 Winner: Royal Challengers Bengaluru (RCB) won the 18th Edition of TATA IPL; Check Overall Team Performance ', 'description': 'Royal Challengers Bengaluru (RCB) clinched the IPL 2025 title, ending an 11-year wait to become champions in the 18th TATA IPL edition. Explore their stellar team performance, key players, and standout moments that led to their historic victory against RCB in the final.', 'language': 'en'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3: Initialize the Embedding Model\n",
        "Google's ecosystem (Gemini LLM), the most natural choice for embeddings is Google's GoogleGenerativeAIEmbeddings (which uses models like text-embedding-004 or embedding-001). This also runs via API, so no local RAM issues!\n",
        "\n"
      ],
      "metadata": {
        "id": "TSV7dvAOCsEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5. Establish the knowledge base and retriever (Part 3: Initialize Embedding Model) ---\n",
        "\n",
        "# Import the Google Embeddings class\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "# Initialize the embedding model with the correct model name format\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/embedding-001\" # CORRECTED: Added \"models/\" prefix\n",
        ")\n",
        "\n",
        "print(\"\\nEmbedding model (GoogleGenerativeAIEmbeddings) initialized with correct model name.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF7HszKHCObR",
        "outputId": "ec8342f5-5fba-4b15-b44d-8cf6543165f1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Embedding model (GoogleGenerativeAIEmbeddings) initialized with correct model name.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 4: Create the Vector Store (Chroma DB)"
      ],
      "metadata": {
        "id": "kIWD93saDB11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5. Establish the knowledge base and retriever (Part 4: Create Vector Store) ---\n",
        "\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Create the Chroma vector store from our document chunks and embeddings\n",
        "print(\"Creating Chroma vector store... This may take a moment.\")\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"ipl-2025-rag-chroma\",\n",
        "    embedding=embeddings,\n",
        ")\n",
        "print(\"Vector store created and documents embedded.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyC-RX2OCOfo",
        "outputId": "60100708-add2-4d0e-97fc-1450982313bd"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Chroma vector store... This may take a moment.\n",
            "Vector store created and documents embedded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 5. Establish the knowledge base and retriever (Part 5: Set up Retriever) ---\n",
        "\n",
        "# Set up the retriever from the vector store\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "print(\"Retriever set up.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la0n8FZCCOh5",
        "outputId": "3dddea29-fbf5-4a68-b600-8a77cdb60731"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retriever set up.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 6. Define the agent's RAG tool ---\n",
        "\n",
        "from langchain.tools import tool\n",
        "\n",
        "# Define the RAG tool for IPL 2025 context\n",
        "@tool\n",
        "def get_ipl_2025_context(question: str):\n",
        "    \"\"\"Get context about the Indian Premier League (IPL) 2025, including team performance and the winner.\"\"\"\n",
        "    context = retriever.invoke(question)\n",
        "    return context\n",
        "\n",
        "# List of tools available to the agent\n",
        "tools = [get_ipl_2025_context]\n",
        "\n",
        "print(\"RAG tool 'get_ipl_2025_context' defined and added to tools list.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ib1Tj4Ch1MoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32ea921d-2a46-448d-dc0d-a733b4f506f5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG tool 'get_ipl_2025_context' defined and added to tools list.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 7. Establish the prompt template (Structured Chat Prompt) ---\n",
        "\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.tools.render import render_text_description_and_args\n",
        "\n",
        "# Define the system prompt with instructions for JSON output and thought process\n",
        "# The {tools} and {tool_names} placeholders will be filled later.\n",
        "system_prompt = \"\"\"Respond to the human as helpfully and accurately as possible. You have access to the following tools: {tools}\n",
        "\n",
        "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
        "\n",
        "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
        "\n",
        "Provide only ONE action per $JSON_BLOB, as shown:\"\n",
        "\n",
        "```json\n",
        "{{\n",
        "\"action\": $TOOL_NAME,\n",
        "\"action_input\": $INPUT\n",
        "}}"
      ],
      "metadata": {
        "id": "OKrovYLYGKkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 7. Define the agent's prompt (COMPLETE BLOCK) ---\n",
        "\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain.tools.render import render_text_description_and_args # Needed to render tool descriptions for the prompt\n",
        "\n",
        "# This defines the strict format the agent must follow for its thoughts and actions.\n",
        "# {tools} and {tool_names} will be dynamically inserted by LangChain.\n",
        "system_prompt = \"\"\"Respond to the human as helpfully and accurately as possible. You have access to the following tools: {tools}\n",
        "\n",
        "Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).\n",
        "\n",
        "Valid \"action\" values: \"Final Answer\" or {tool_names}\n",
        "\n",
        "Provide only ONE action per $JSON_BLOB, as shown:\"\n",
        "\n",
        "```\n",
        "\n",
        "{{\n",
        "\n",
        "\"action\": $TOOL_NAME,\n",
        "\n",
        "\"action_input\": $INPUT\n",
        "\n",
        "}}\n",
        "\n",
        "```\n",
        "\n",
        "Follow this format:\n",
        "\n",
        "Question: input question to answer\n",
        "\n",
        "Thought: consider previous and subsequent steps\n",
        "\n",
        "Action:\n",
        "\n",
        "$JSON_BLOB\n",
        "\n",
        "```\n",
        "\n",
        "Observation: action result\n",
        "\n",
        "... (repeat Thought/Action/Observation N times)\n",
        "\n",
        "Thought: I know what to respond\n",
        "\n",
        "Action:\n",
        "\n",
        "```\n",
        "\n",
        "{{\n",
        "\n",
        "\"action\": \"Final Answer\",\n",
        "\n",
        "\"action_input\": \"Final response to human\"\n",
        "\n",
        "}}\n",
        "\n",
        "Begin! Reminder to ALWAYS respond with a valid json blob of a single action.\n",
        "\n",
        "Respond directly if appropriate. Format is Action:```$JSON_BLOB```then Observation\"\"\"\n",
        "\n",
        "print(\"Agent system prompt format defined.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sk5RP9hfHzQa",
        "outputId": "89c80af4-12fd-449f-e0cd-5fe7a8641ea0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent system prompt format defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "human_prompt = \"\"\"{input}\n",
        "\n",
        "{agent_scratchpad}\n",
        "\n",
        "(reminder to always respond in a JSON blob)\"\"\"\n",
        "print(\"Human prompt format defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzfwGQBZHzSz",
        "outputId": "7a345690-0639-4662-f8d4-40f389e42b18"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human prompt format defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 7. Define the agent's prompt (Part 3: Final ChatPromptTemplate Assembly) ---\n",
        "\n",
        "# Combine the system_prompt, optional chat_history, and human_prompt into the final ChatPromptTemplate\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system_prompt),\n",
        "        MessagesPlaceholder(\"chat_history\", optional=True),\n",
        "        (\"human\", human_prompt),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Final ChatPromptTemplate assembled.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAg7XY6pGKqa",
        "outputId": "3acfd9e5-d058-4985-d85d-791d44695363"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final ChatPromptTemplate assembled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 7. Define the agent's prompt (Part 4: Partial Prompt for Tools) ---\n",
        "\n",
        "# This step \"partials\" the prompt with the dynamically generated tool descriptions and names.\n",
        "# `render_text_description_and_args` formats the tool for the prompt's `tools` variable.\n",
        "# `tool_names` populates the `{tool_names}` variable in the system prompt.\n",
        "prompt = prompt.partial(\n",
        "    tools=render_text_description_and_args(list(tools)), # 'tools' is our list from Step 6\n",
        "    tool_names=\", \".join([t.name for t in tools]),\n",
        ")\n",
        "\n",
        "print(\"Prompt template finalized with tool information.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5qFUNesJAdH",
        "outputId": "b8a5edb4-00e4-416a-9cfc-801d414ce6d0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt template finalized with tool information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 8. Set up the agent's memory and chain (COMPLETE BLOCK) ---\n",
        "\n",
        "# Imports for this step (ensure they are all present)\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain.agents.format_scratchpad import format_log_to_str\n",
        "from langchain.agents.output_parsers import JSONAgentOutputParser\n",
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "# 1. Set up the agent's memory\n",
        "memory = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\", # Ensure this matches the MessagesPlaceholder name in your prompt\n",
        "    return_messages=True      # Store history as a list of message objects\n",
        ")\n",
        "print(\"ConversationBufferMemory initialized.\")\n",
        "\n",
        "# 2. Set up the chain with agent's scratchpad, memory, prompt, and LLM\n",
        "# This chain defines the flow:\n",
        "# Input -> Format scratchpad/chat history -> Prompt -> LLM (thinks/acts) -> Parse LLM's JSON output\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(\n",
        "        # `intermediate_steps` contains tuples of (AgentAction, observation)\n",
        "        # `format_log_to_str` converts these into a string digestible by the LLM\n",
        "        agent_scratchpad=lambda x: format_log_to_str(x[\"intermediate_steps\"]),\n",
        "        # `chat_history` comes directly from the memory buffer\n",
        "        chat_history=lambda x: memory.chat_memory.messages,\n",
        "    )\n",
        "    | prompt # Our carefully crafted prompt from Step 7\n",
        "    | llm    # Our Gemini LLM\n",
        "    | JSONAgentOutputParser() # Parses the LLM's JSON output into AgentAction or AgentFinish\n",
        ")\n",
        "print(\"Agent chain (RunnablePassthrough | prompt | llm | JSONAgentOutputParser) defined.\")\n",
        "\n",
        "# 3. Initialize the AgentExecutor\n",
        "# This brings everything together: the agent's core logic (chain), its tools, memory, etc.\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=chain,\n",
        "    tools=tools, # Our `tools` list containing `get_ipl_2025_context`\n",
        "    handle_parsing_errors=True, # Important for robustness if LLM doesn't follow JSON format exactly\n",
        "    verbose=True, # Will show the agent's thought process (Thought, Action, Observation)\n",
        "    memory=memory # Connects the memory to the executor\n",
        ")\n",
        "print(\"AgentExecutor initialized.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptCJWvEAJAf4",
        "outputId": "a32a80b3-4c0e-48db-eb62-6c5f192e9fa4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConversationBufferMemory initialized.\n",
            "Agent chain (RunnablePassthrough | prompt | llm | JSONAgentOutputParser) defined.\n",
            "AgentExecutor initialized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-24-2570823533.py:11: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9. Generate responses with the agentic RAG system"
      ],
      "metadata": {
        "id": "vlxytnN2Kj8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 9. Generate responses with the agentic RAG system\n",
        "\n",
        "print(\"--- Testing Agent with RAG Tool (IPL 2025 Queries) ---\")\n",
        "\n",
        "# 1. Ask a question that requires the agent to use its RAG tool (IPL 2025 winner)\n",
        "question_ipl_winner = \"Who won the IPL 2025 tournament and where was the final played?\"\n",
        "print(f\"\\nAsking the agent: '{question_ipl_winner}'\")\n",
        "\n",
        "# Invoke the agent executor with verbose output\n",
        "response_ipl_winner = agent_executor.invoke({\"input\": question_ipl_winner})\n",
        "\n",
        "print(\"\\nAgent's Final Answer for IPL 2025 Winner:\")\n",
        "print(response_ipl_winner[\"output\"])\n",
        "\n",
        "# 2. Ask a slightly more complex question about IPL 2025 details\n",
        "question_ipl_details = \"Tell me about the key players and their performance for the IPL 2025 winning team.\"\n",
        "print(f\"\\nAsking the agent: '{question_ipl_details}'\")\n",
        "\n",
        "response_ipl_details = agent_executor.invoke({\"input\": question_ipl_details})\n",
        "\n",
        "print(\"\\nAgent's Final Answer for IPL 2025 Details:\")\n",
        "print(response_ipl_details[\"output\"])\n",
        "\n",
        "# 3. Test if the agent can decipher when tool calling is not necessary (general knowledge)\n",
        "question_general = 'What is the capital of France?'\n",
        "print(f\"\\nAsking the agent: '{question_general}'\")\n",
        "\n",
        "response_general = agent_executor.invoke({\"input\": question_general})\n",
        "\n",
        "print(\"\\nAgent's Final Answer for General Knowledge:\")\n",
        "print(response_general[\"output\"])\n",
        "\n",
        "print(\"\\n--- End of Agent Testing ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duQPmF_SKkED",
        "outputId": "83d6e560-1a2e-48e4-9c0b-b2fcf79f1781"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Agent with RAG Tool (IPL 2025 Queries) ---\n",
            "\n",
            "Asking the agent: 'Who won the IPL 2025 tournament and where was the final played?'\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "  \"action\": \"get_ipl_2025_context\",\n",
            "  \"action_input\": {\n",
            "    \"question\": \"Who won the IPL 2025 tournament and where was the final played?\"\n",
            "  }\n",
            "}\n",
            "```\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(metadata={'title': '2025 Indian Premier League - Wikipedia', 'language': 'en', 'source': 'https://en.wikipedia.org/wiki/2025_Indian_Premier_League'}, page_content='Suspension and rescheduling\\nOn 9 May 2025, the remaining matches were suspended due to the 2025 India–Pakistan crisis.[15] The revised schedule was announced on 12 May, with the remaining matches resumed on 17 May and were held across six venues.[16][17] On 20 May the playoff fixtures were confirmed[18] with Qualifier 1 and Eliminator played in Maharaja Yadavindra Singh International Cricket Stadium on 29 and 30 May, and Qualifier 2 and final played at Narendra Modi Stadium on 1 and 3 June,[19] with the venue hosting its third final after 2022 and 2023.[20] The final was played on 3 June, just a week before the 2025 ICC World Test Championship final scheduled for 11 June.[21]\\n\\nMarketing\\nThe Tata Group renewed their contract as the title sponsors of the IPL for a tenure of 5 years (2024–28) for ₹2,500 crore (US$300\\xa0million).[22] The advertising campaign for the 2025 IPL consisted of 20 sponsors and 105 advertisers[23][24] including  –  Dream11, Tata Motors, AngelOne, RuPay, CEAT and Wonder Cement.[25]'), Document(metadata={'title': '2025 Indian Premier League - Wikipedia', 'language': 'en', 'source': 'https://en.wikipedia.org/wiki/2025_Indian_Premier_League'}, page_content='^ \"Eden Gardens to host IPL 2025 final on May 25\". ESPNcricinfo. Retrieved 16 February 2025.\\n\\n^ \"IPL 2025 suspended amid India-Pakistan border tensions\". ESPNcricinfo. 9 May 2025. Archived from the original on 9 May 2025. Retrieved 14 May 2025.\\n\\n^ a b \"Remainder of IPL 2025 to be held at six venues\". IPLT20.com. 12 May 2025. Archived from the original on 14 May 2025. Retrieved 14 May 2025.\\n\\n^ a b \"IPL 2025 to resume on May 17 with RCB vs KKR, final scheduled for June 3\". ESPNcricinfo. 14 May 2025. Archived from the original on 14 May 2025. Retrieved 14 May 2025.\\n\\n^ a b c d e f \"Schedule for TATA IPL 2025 Playoffs announced\". IPLT20.com. 20 May 2025. Archived from the original on 28 May 2025. Retrieved 24 May 2025.\\n\\n^ \"IPL 2025: Ahmedabad to host final as RCB match moved amid Bengaluru rain\". BBC Sport. 20 May 2025. Retrieved 24 May 2025.'), Document(metadata={'language': 'en', 'title': '2025 Indian Premier League - Wikipedia', 'source': 'https://en.wikipedia.org/wiki/2025_Indian_Premier_League'}, page_content=\"Broadcasting\\nDisney Star's Star Sports and Viacom18's JioCinema had initially acquired the satellite and digital broadcasting rights for the 2023–2027 IPL cycle respectively.[26] In November 2024, the two companies merged to form JioStar.[27] In February 2025, JioCinema and Disney+ Hotstar merged to form JioHotstar, which now holds the domestic digital broadcasting rights for the remainder of the 2023–2027 cycle.[28]\\nIn the opening weekend of three matches, Star Sports reported 253 million viewership, with a 39% increase in the average television viewership rating compared to last season, while JioHotstar reported 1.37 billion viewership, a 40% increase from last season.[29][30] The final match reported a record-breaking 169 million viewership.[31]\\n\\nTeams\\nThe same 10 teams from the previous season competed.\\n\\n\\n\\nGroup\\nTeam\\n2024 performance[32]\\nHead coach[33]\\nCaptain[33]\\n\\n\\nA\\n\\nChennai Super Kings\\n5th\\nStephen Fleming\\nMS Dhoni[a]\"), Document(metadata={'source': 'https://en.wikipedia.org/wiki/2025_Indian_Premier_League', 'title': '2025 Indian Premier League - Wikipedia', 'language': 'en'}, page_content='2025 Indian Premier League - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nBackground\\n\\n\\n\\n\\nToggle Background subsection\\n\\n\\n\\n\\n\\n1.1\\nFormat\\n\\n\\n\\n\\n\\n\\n1.1.1\\nRule changes')]\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"I am sorry, but I do not have access to the results of the IPL 2025 tournament.  My knowledge about this topic is limited.\"\n",
            "}\n",
            "```\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Agent's Final Answer for IPL 2025 Winner:\n",
            "I am sorry, but I do not have access to the results of the IPL 2025 tournament.  My knowledge about this topic is limited.\n",
            "\n",
            "Asking the agent: 'Tell me about the key players and their performance for the IPL 2025 winning team.'\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "  \"action\": \"get_ipl_2025_context\",\n",
            "  \"action_input\": {\n",
            "    \"question\": \"Tell me about the key players and their performance for the IPL 2025 winning team.\"\n",
            "  }\n",
            "}\n",
            "```\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m[Document(metadata={'source': 'https://en.wikipedia.org/wiki/2025_Indian_Premier_League', 'language': 'en', 'title': '2025 Indian Premier League - Wikipedia'}, page_content=\"Broadcasting\\nDisney Star's Star Sports and Viacom18's JioCinema had initially acquired the satellite and digital broadcasting rights for the 2023–2027 IPL cycle respectively.[26] In November 2024, the two companies merged to form JioStar.[27] In February 2025, JioCinema and Disney+ Hotstar merged to form JioHotstar, which now holds the domestic digital broadcasting rights for the remainder of the 2023–2027 cycle.[28]\\nIn the opening weekend of three matches, Star Sports reported 253 million viewership, with a 39% increase in the average television viewership rating compared to last season, while JioHotstar reported 1.37 billion viewership, a 40% increase from last season.[29][30] The final match reported a record-breaking 169 million viewership.[31]\\n\\nTeams\\nThe same 10 teams from the previous season competed.\\n\\n\\n\\nGroup\\nTeam\\n2024 performance[32]\\nHead coach[33]\\nCaptain[33]\\n\\n\\nA\\n\\nChennai Super Kings\\n5th\\nStephen Fleming\\nMS Dhoni[a]\"), Document(metadata={'language': 'en', 'title': '2025 Indian Premier League - Wikipedia', 'source': 'https://en.wikipedia.org/wiki/2025_Indian_Premier_League'}, page_content='Group B\\n\\nMumbai Indians\\nSunrisers Hyderabad\\nGujarat Titans\\nDelhi Capitals\\nLucknow Super Giants\\n\\n\\nNote: Teams are listed per the playing order.viewtalkedit\\nThe 2025 Indian Premier League, also known as IPL 18 and branded as TATA IPL 2025, was the 18th edition of the Indian Premier League, a professional Twenty20 cricket league. The tournament featured 10 teams competing in 74 matches. It began on 22 March and was held across 13 venues before being suspended on 9 May due to the 2025 India–Pakistan crisis. The matches resumed from 17 May across six venues, with the final rescheduled from 25 May to 3 June.\\nThe defending champions Kolkata Knight Riders were eliminated in the league stage. In the final, Royal Challengers Bengaluru defeated Punjab Kings by 6 runs to win their maiden title after 18 years. Sai Sudharsan and Prasidh Krishna of Gujarat Titans scored the most runs (759) and took the most wickets (25) respectively. Suryakumar Yadav of Mumbai Indians was awarded as the most valuable player of the tournament.'), Document(metadata={'title': '2025 Indian Premier League - Wikipedia', 'language': 'en', 'source': 'https://en.wikipedia.org/wiki/2025_Indian_Premier_League'}, page_content='^ \"IPL 2025: Corbin Bosch makes debut for Mumbai Indians against LSG at home\". Business Standard. Archived from the original on 28 April 2025. Retrieved 28 May 2025.\\n\\n^ \"DC vs RCB IPL 2025 Highlights: Tim David finishes off in style as Bengaluru win by 6 wickets\". Firstpost. 27 April 2025. Retrieved 28 May 2025.\\n\\n^ \"Who is Karim Janat? Gujarat Titans debutant, becoming 10th Afghanistan player to feature in IPL during RR vs GT\". Live Mint. 28 April 2025. Retrieved 21 June 2025.\\n\\n^ \"IPL 2025: 14-year-old Vaibhav Suryavanshi smashes 35-ball hundred, breaks world record\". India Today. 28 April 2025. Retrieved 28 April 2025.\\n\\n^ \"IPL 2025: Yuzvendra Chahal picks hat-trick for Punjab Kings against Chennai Super Kings\". Sportstar. 30 April 2025. Retrieved 30 April 2025.\\n\\n^ \"Shreyas, Prabhsimran and Chahal eliminate CSK\". ESPNcricinfo. Retrieved 30 April 2025.'), Document(metadata={'source': 'https://en.wikipedia.org/wiki/2025_Indian_Premier_League', 'language': 'en', 'title': '2025 Indian Premier League - Wikipedia'}, page_content='^ \"RCB\\'s Maiden IPL Win Breaks All-Time TV Viewership Record: 169 Million Tuned In\". Times Now. 14 June 2025. Retrieved 15 June 2025.\\n\\n^ 2024 Indian Premier League points table standings at ESPNcricinfo. Archived from the original on 26 May 2025. Retrieved 30 October 2024.\\n\\n^ a b \"IPL 2025: Who Are The Captains And Coaching Staff Of Each Team? | Indian Premier League | India Cricket News\". Wisden. 18 March 2025. Retrieved 10 April 2025.\\n\\n^ \"Ruturaj Gaikwad ruled out of IPL 2025, MS Dhoni set to lead Chennai Super Kings\". The Indian Express. 10 April 2025. Retrieved 10 April 2025.\\n\\n^ \"IPL 2025: Parag named Royals captain for first three games, Samson to play as batter\". ESPNcricinfo. 20 March 2025. Retrieved 17 June 2025.\\n\\n^ \"Rahul Dravid reserves special praise for Riyan Parag\\'s captaincy\". Crictoday. 21 May 2025. Retrieved 16 June 2025.')]\u001b[0m\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"The Royal Challengers Bangalore won the IPL 2025 tournament.  While the provided text mentions key players like Sai Sudharsan and Prasidh Krishna (who led in runs and wickets respectively for a different team), it doesn't detail the specific performance of key players for the winning RCB team.  The text only states that they won by 6 runs against the Punjab Kings in the final.\"\n",
            "}\n",
            "```\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Agent's Final Answer for IPL 2025 Details:\n",
            "The Royal Challengers Bangalore won the IPL 2025 tournament.  While the provided text mentions key players like Sai Sudharsan and Prasidh Krishna (who led in runs and wickets respectively for a different team), it doesn't detail the specific performance of key players for the winning RCB team.  The text only states that they won by 6 runs against the Punjab Kings in the final.\n",
            "\n",
            "Asking the agent: 'What is the capital of France?'\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"The capital of France is Paris.\"\n",
            "}\n",
            "```\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Agent's Final Answer for General Knowledge:\n",
            "The capital of France is Paris.\n",
            "\n",
            "--- End of Agent Testing ---\n"
          ]
        }
      ]
    }
  ]
}